{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff47213",
   "metadata": {},
   "source": [
    "## 0. Review \n",
    "### 1. 파이프 만들기\n",
    "- pipeline.pkl에 파이프라인 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ea3140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\owner\\\\Documents\\\\week3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Scaling ->MinMax,  Imputing-> mean, pkl 파일 생성해주세요.\n",
    "\n",
    "# CSV 읽기\n",
    "csv_path = \"data.csv\"      # <- 파일명 수정\n",
    "target_col = \"Pass.Fail\"      # <- 타깃 컬럼명 수정\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=[target_col]) #df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "# 전처리(결측치 + 스케일링 + 원핫)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_include=\"number\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_exclude=\"number\"))\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess)\n",
    "])\n",
    "\n",
    "with open(\"pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump( { \"pipeline\": pipe},  f )\n",
    "    \n",
    "# 적용\n",
    "X_piped = pipe.fit_transform(X)\n",
    "X_processed = pd.DataFrame(X_piped, columns=X.columns)\n",
    "X_processed[target_col] = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3eddf9",
   "metadata": {},
   "source": [
    "### 2. API 만들기\n",
    "- API URL을 호출하면 JSON으로 정해진 행들을 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.py 파일 \n",
    "#pkl 읽으셔서 데이터프레임에 pipe로 전처리를 적용하신 후, 데이터프레임으로 만드셔서\n",
    "#api로 서비스해보세요.\n",
    "#with open(\"파일이름.pkl\", \"rb\") as f:\n",
    "# saved = pickle.load(f)\n",
    "# saved[\"pipeline\"]  \n",
    "from fastapi import FastAPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "app = FastAPI()\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "@app.get(\"/data\")\n",
    "def date_gen():\n",
    "    x = df.sample( 5 )   \n",
    "    return  x.to_dict(orient=\"records\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e730ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X20</th>\n",
       "      <th>X86</th>\n",
       "      <th>X87</th>\n",
       "      <th>X88</th>\n",
       "      <th>X113</th>\n",
       "      <th>X115</th>\n",
       "      <th>X116</th>\n",
       "      <th>X117</th>\n",
       "      <th>X119</th>\n",
       "      <th>X120</th>\n",
       "      <th>...</th>\n",
       "      <th>X527</th>\n",
       "      <th>X570</th>\n",
       "      <th>X571</th>\n",
       "      <th>X572</th>\n",
       "      <th>X573</th>\n",
       "      <th>X574</th>\n",
       "      <th>X575</th>\n",
       "      <th>X576</th>\n",
       "      <th>X577</th>\n",
       "      <th>Pass.Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4144</td>\n",
       "      <td>2.4021</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>1811.5779</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>784.3665</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>59.0527</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>6.4008</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5111</td>\n",
       "      <td>533.4909</td>\n",
       "      <td>1.6300</td>\n",
       "      <td>8.6801</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>3.0031</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>1.6270</td>\n",
       "      <td>7.9951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3890</td>\n",
       "      <td>2.4398</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>1791.7535</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>637.5776</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>58.9508</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>6.2960</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7528</td>\n",
       "      <td>531.8455</td>\n",
       "      <td>2.2544</td>\n",
       "      <td>8.6400</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>3.0979</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>1.6245</td>\n",
       "      <td>13.2830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X20     X86     X87        X88    X113      X115    X116     X117  \\\n",
       "0  1.4144  2.4021  0.9850  1811.5779  0.9446  784.3665  0.9904  59.0527   \n",
       "1  1.3890  2.4398  0.9915  1791.7535  0.9467  637.5776  0.9906  58.9508   \n",
       "\n",
       "     X119    X120  ...    X527      X570    X571    X572    X573    X574  \\\n",
       "0  0.9659  6.4008  ...  7.5111  533.4909  1.6300  8.6801  0.1303  3.0031   \n",
       "1  0.9791  6.2960  ...  8.7528  531.8455  2.2544  8.6400  0.2994  3.0979   \n",
       "\n",
       "     X575    X576     X577  Pass.Fail  \n",
       "0  0.0397  1.6270   7.9951          0  \n",
       "1  0.0888  1.6245  13.2830          0  \n",
       "\n",
       "[2 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "r = requests.get(\"http://localhost:8000/data?row=2\")\n",
    "pd.DataFrame( r.json() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfcc411",
   "metadata": {},
   "source": [
    "## DuckDB (덕DB): 분석(OLAP) 전용 임베디드 DB임, 컬럼 지향 구조라 대용량 집계·통계 처리 빠름, Parquet·CSV 파일을 로딩 없이 SQL로 바로 조회 가능함\n",
    "- 단점: 다중 사용자 동시 접속 부적합함, 트랜잭션·권한 관리 기능 약함, 서비스용 운영 DB로 쓰기엔 부적절함\n",
    "- 적합: EDA, 피처엔지니어링, 실험 분석용, ML 전처리·중간 결과 저장용\n",
    "\n",
    "## SQLite: 파일 기반 경량 임베디드 DB임, 설치·설정 거의 필요 없음, 단일 파일로 관리·배포 쉬움\n",
    "- 단점: 동시 쓰기 성능 매우 약함, 대용량 분석 성능 한계 있음, 사용자·권한·스키마 관리 기능 부족함\n",
    "- 적합: 로컬 저장소, 소규모 단일 사용자 환경, 임시 결과 저장용\n",
    "\n",
    "## PostgreSQL: 서버형 관계형 DB임, 다중 사용자·트랜잭션 처리에 강함, 권한·스키마·백업 체계 완성도 높음, 서비스 백엔드용으로 적합함\n",
    "- 단점: 설치·운영 부담 있음, 로컬 단일 분석에는 과함, 대용량 분석 성능은 DuckDB보다 느릴 수 있음\n",
    "- 적합: 운영 서비스 DB, 다중 사용자 시스템, 장기 데이터 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d98a9",
   "metadata": {},
   "source": [
    "## 1. sqlite 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8b0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"score\": [0.8, 0.6, 0.9],\n",
    "    \"label\": [1, 0, 1]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75545d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api 결과를 데이터프레임으로 만드신 후에 sqlite에 apitable이라는 테이블에다가 저장\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import requests\n",
    "r = requests.get(\"http://localhost:8000/data?row=2\")\n",
    "df=pd.DataFrame( r.json())   \n",
    "engine = create_engine(\"sqlite:///example.db\")\n",
    "df.to_sql( \"apitable\", engine,  if_exists=\"append\", index=False)\n",
    "df_check = pd.read_sql_query( \"SELECT * FROM apitable\", engine)\n",
    "print(df_check.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acea9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.types import Integer, Float, Text\n",
    "df.to_sql(\n",
    "    \"model_result\",\n",
    "    engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype={\n",
    "        \"id\": Integer(),\n",
    "        \"score\": Float(),\n",
    "        \"label\": Integer(),\n",
    "        \"comment\": Text()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e221397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  score  label\n",
      "0   1    0.8      1\n",
      "1   2    0.6      0\n",
      "2   3    0.9      1\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.read_sql_query(\n",
    "    \"SELECT * FROM model_result\",\n",
    "    engine\n",
    ")\n",
    "print(df_check.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d99ed5",
   "metadata": {},
   "source": [
    "## 2. duckdb 사용\n",
    "- sqlalchemy보다는 connection 스타일 사용 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 기반으로 덕디비에 테이블을 생성해주세요\n",
    "#creditset2.csv를 읽으셔서\n",
    "#default10yr가 1인 레코드만 select해보세요.\n",
    "\n",
    "import duckdb\n",
    "con = duckdb.connect(\"example.duckdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73c9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인메모리 기반\n",
    "con = duckdb.connect(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606782fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")   \n",
    "#API로 부터 데이터를 세 번 받아서 각각 df_2026_02_10_10_27_24.parquet 같은 이름으로 워킹디렉토리 밑 test라는 폴더에 파일들을 만드세요\n",
    "import os\n",
    "os.getcwd()\n",
    "if os.path.exists(\"test\") ==0:\n",
    "    os.mkdir(\"test\")\n",
    "for i in range(4):\n",
    "    df = pd.DataFrame( requests.get(\"http://localhost:8000/data?row=20\").json())\n",
    "    df.to_parquet(\n",
    "        \"test\\\\df\"+datetime.now().strftime(\"%H_%M_%S\")+\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a9bd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0   -0.139556 -0.519279  0.863004  1.354490 -0.034447  0.195597 -0.885449   \n",
      "1   -2.083365 -1.187373 -0.158658  1.326465  1.237458 -2.225531  0.260611   \n",
      "2    2.169757  0.834115  0.562515 -0.781065  0.135140 -0.424901  0.323409   \n",
      "3    1.197852  1.278555  0.790887  0.235043  0.506112  0.553008  0.213513   \n",
      "4    0.034889  0.834115  0.911083 -1.307305 -0.903583 -0.554909  0.339108   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "155 -0.529551  0.173903  0.570773  0.671227  0.074266  0.439508  0.435393   \n",
      "156  0.623375  1.040826  0.580555  0.081343 -0.620055  0.396110  0.363822   \n",
      "157 -0.744233 -1.687737  0.463172 -1.586939 -0.171822 -1.837707  0.459250   \n",
      "158 -1.873305  1.565815 -2.177937  0.978443 -1.402264 -0.009731  0.399607   \n",
      "159  0.249668 -0.568681 -1.718188  0.176785 -1.384687 -0.834613  0.292250   \n",
      "\n",
      "            7         8         9  ...        39        40        41  \\\n",
      "0   -0.905712 -0.340911  0.532030  ...  0.350289  0.952763 -1.541688   \n",
      "1   -1.311852 -0.268951  0.720961  ...  1.566593  0.462876  0.667938   \n",
      "2    0.365790  1.386131  0.548083  ...  1.424129  0.838855 -0.069237   \n",
      "3   -1.537144  1.799901 -0.738619  ... -0.411190 -1.289185  0.435789   \n",
      "4   -0.967852  0.468640 -1.764770  ...  0.305428 -0.368826  1.674461   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "155 -0.550002 -0.749102  0.048980  ... -0.535564 -0.251363 -0.761575   \n",
      "156 -0.262682  1.861750 -1.176985  ...  0.099003 -0.616505 -0.402408   \n",
      "157 -1.085193 -0.840178  0.240833  ... -2.145167 -0.761836 -0.830599   \n",
      "158  0.064884 -0.354438 -0.507682  ...  0.606180 -2.688499 -0.438124   \n",
      "159  1.016924 -1.052689  0.962459  ...  0.294197 -0.239946  0.541058   \n",
      "\n",
      "           42        43        44        45        46        47   48  \n",
      "0   -0.591572 -0.890945 -0.566573 -0.797827 -0.605296 -0.772190  0.0  \n",
      "1   -0.700163  0.390099 -0.493307  0.248747 -0.705870  0.293064  0.0  \n",
      "2   -0.877857 -0.453259 -1.291276 -0.476428 -0.888111 -0.527621  0.0  \n",
      "3    1.289020  0.784336  1.167339  0.551241  1.315065  0.867781  0.0  \n",
      "4    2.162681  3.582417  1.480822  3.761185  2.166399  3.244696  0.0  \n",
      "..        ...       ...       ...       ...       ...       ...  ...  \n",
      "155 -0.236384 -0.677266 -0.241362 -0.562421 -0.236095 -0.540913  0.0  \n",
      "156 -0.206255 -0.324970 -0.202894 -0.389807 -0.206164 -0.246285  0.0  \n",
      "157 -0.221373 -0.507661 -0.218229 -0.423063 -0.221003 -0.349824  0.0  \n",
      "158  4.358234  3.847611  4.358097  3.999976  4.358249  3.953869  0.0  \n",
      "159 -0.229415 -0.354808 -0.227885 -0.345466 -0.229235 -0.439299  0.0  \n",
      "\n",
      "[160 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "con.execute(\"\"\"CREATE TABLE model_result4 AS\n",
    "SELECT * FROM 'test/*.parquet'\"\"\")\n",
    "df_out = con.execute(\"\"\" SELECT * FROM model_result4\"\"\").df()\n",
    "print(df_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44b2bd",
   "metadata": {},
   "source": [
    "- Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8953eb",
   "metadata": {},
   "source": [
    "- api로 데이터를 가져오셔서 덕디비에 넣어주세요.\n",
    "- api로 데이터 가져오셔서 parquet로 만드신 후에, 덕디비에서 읽어주세요.\n",
    "- 데이터프레임.to_parquet(\"이름.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a60e4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1c52d58c370>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "INSERT INTO model_result\n",
    "SELECT * FROM df\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6eab8",
   "metadata": {},
   "source": [
    "- 파퀘, csv 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ae968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM '이름.parquet'\n",
    "WHERE label = 1\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75004f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM read_csv_auto('data.csv')\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd1030",
   "metadata": {},
   "source": [
    "- 테이블 등록 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b47d2e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1c52d58c370>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.register(\"tmp_df\", df)\n",
    "con.execute(\"CREATE TABLE t AS SELECT * FROM tmp_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee30b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = con.execute(\"SELECT * FROM t\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ead68bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmp_df</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name\n",
       "0       t\n",
       "1  tmp_df"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SHOW TABLES\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "200394fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1c52d58c370>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS model_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd164c",
   "metadata": {},
   "source": [
    "- parquet + duckdb\n",
    " - Parquet: 컬럼 지향 파일 포맷 (빠름, 압축 좋음)\n",
    " - DuckDB: Parquet를 로드 없이 SQL로 바로 조회 가능한 분석용 DB, read_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "330be016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parquet 파일 생성\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"user_id\": [1, 2, 3, 4],\n",
    "    \"age\": [23, 35, 29, 41],\n",
    "    \"score\": [88.5, 72.0, 91.2, 65.3]\n",
    "})\n",
    "\n",
    "df.to_parquet(\"sample.parquet\", engine=\"pyarrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec6cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  avg_score\n",
      "0   23       88.5\n",
      "1   29       91.2\n",
      "2   35       72.0\n",
      "3   41       65.3\n"
     ]
    }
   ],
   "source": [
    "#parquet에 대해 직접 쿼리\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        age,\n",
    "        AVG(score) AS avg_score\n",
    "    FROM read_parquet('sample.parquet')\n",
    "    GROUP BY age\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc8ffc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#폴더 내 여러 parquet 파일에 대해 쿼리\n",
    "con.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM read_parquet('*.parquet')\n",
    "\"\"\").fetchone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4627074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  count_star()\n",
       "0   23             1\n",
       "1   29             1\n",
       "2   35             1\n",
       "3   41             1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parquet 파일을 테이블로 생성 후 쿼리\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE users AS\n",
    "    SELECT * FROM read_parquet('sample.parquet')\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    SELECT age, COUNT(*) \n",
    "    FROM users\n",
    "    GROUP BY age\n",
    "\"\"\").fetchdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b597eace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x238b9438af0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas → DuckDB\n",
    "con.register(\"df_users\", df)\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE users2 AS\n",
    "    SELECT * FROM df_users\n",
    "\"\"\")\n",
    "\n",
    "# DuckDB → Parquet\n",
    "con.execute(\"\"\"\n",
    "    COPY users2 TO 'users2.parquet' (FORMAT PARQUET)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7e019",
   "metadata": {},
   "source": [
    "## 3. Postgres SQL 접속을 위한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd11cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0027196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql+psycopg2://postgres:12345@localhost:5432/postgres'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_INFO = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"12345\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"postgres\",\n",
    "}\n",
    "\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**DB_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53aaa76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**DB_INFO)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f670b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"score\": [0.8, 0.6, 0.9],\n",
    "    \"label\": [1, 0, 1]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api의 데이터를 여러 차례 읽으셔서 pipe로 전처리 하신 후에, 그 결과를\n",
    "# postgres의 apitest테이블에 넣어주세요 append 옵션\n",
    "\n",
    "import pickle\n",
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "    saved = pickle.load(f)\n",
    "pipe = saved['pipeline']\n",
    "# 아래 예제를 수정하셔서, api로 수집한 값을 postgres폴더에 csv로 만드세요\n",
    "# 파일명은 df_시_분_초.csv 형식으로...\n",
    "# 해당 폴더의 파일들을 postgres의 apitest2 테이블에 넣어주세요.\n",
    "if os.path.exists(\"postgres\")==0:\n",
    "    os.mkdir(\"postgres\")\n",
    "\n",
    "engine_sqlite = create_engine(\"sqlite:///파일이름.db\")\n",
    "for i in range(2):\n",
    "    tmp = pd.DataFrame( requests.get(\"http://localhost:8000/data?row=10\").json())\n",
    "    df = pd.DataFrame( pipe.fit_transform(tmp), columns=tmp.columns)\n",
    "    df.to_csv(\"postgres\\\\df\"+ datetime.now().strftime(\"api_%M%S\") +\".csv\")\n",
    "    #log에 해당하는 데이터프레임(한줄짜리) 생성하셔서 sqlite에 저장\n",
    "    #컬럼은 2개-> process, \"data_collect\" / time, \"연-월-일 시-분-초\"\n",
    "    pd.DataFrame( {\"proces\":[\"data_collect\"],\n",
    "                   \"time\": [datetime.now().strftime(\"%H-%M-%S\")]}\n",
    "                   ).to_sql(name=\"sqlite1\", con=engine_sqlite,\n",
    "                            if_exists=\"append\", index=False)\n",
    "\n",
    "for i in os.listdir(\"postgres\"):\n",
    "    df2 = pd.read_csv(i)\n",
    "    df2.to_sql(\n",
    "    name=\"apitest\",   # 테이블명\n",
    "    con=engine,\n",
    "    schema=\"public\",       # 기본 스키마***\n",
    "    if_exists=\"append\",   # 'fail' | 'replace' | 'append'\n",
    "    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f8e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test1', 'apitest']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**DB_INFO)\n",
    ")\n",
    "\n",
    "inspector = inspect(engine)\n",
    "\n",
    "tables = inspector.get_table_names(schema=\"public\")\n",
    "print(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f548c415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM api_save\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6734ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "query = text(\"\"\"\n",
    "    SELECT *\n",
    "    FROM test1\n",
    "\"\"\")\n",
    "\n",
    "df = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd69a31",
   "metadata": {},
   "source": [
    "- Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7adae667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**DB_INFO)\n",
    ")\n",
    "\n",
    "sql = text(\"\"\"\n",
    "INSERT INTO test1 (id, score, label)\n",
    "VALUES (:id, :score, :label)\n",
    "\"\"\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql, {\n",
    "        \"id\": 1,\n",
    "        \"score\": 0.85,\n",
    "        \"label\": 1\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62a2caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"id\": 1, \"score\": 0.8, \"label\": 1},\n",
    "    {\"id\": 2, \"score\": 0.6, \"label\": 0},\n",
    "    {\"id\": 3, \"score\": 0.9, \"label\": 1},\n",
    "]\n",
    "\n",
    "sql = text(\"\"\"\n",
    "INSERT INTO test1 (id, score, label)\n",
    "VALUES (:id, :score, :label)\n",
    "\"\"\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql, rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    row_count = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM public.test1\")\n",
    "    ).scalar()\n",
    "\n",
    "print(row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e179749",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS test1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bfddb",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering - Dimension Reduction\n",
    "- 주성분 분석(Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# data.csv에서 Pass.Fail이 1인 행들만 모아서 주성분분석 수행: ~33\n",
    "#df.query( \"'Pass.Fail'==1\")\n",
    "\n",
    "# df: 원본 데이터프레임\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "X = df.select_dtypes(include=\"number\").dropna().drop(columns=[\"Pass.Fail\"])  # 숫자형만 + 결측 제거(간단 버전)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=20, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "np.sum(pca.explained_variance_ratio_)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b012a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.11536896 0.09728922 0.09325037 0.08397572 0.07928965 0.07018747\n",
      " 0.063275   0.05943407 0.05519337 0.04980041 0.04248545]\n",
      "Cumulative: [0.11536896 0.21265818 0.30590855 0.38988427 0.46917392 0.53936139\n",
      " 0.60263639 0.66207046 0.71726383 0.76706424 0.80954969]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1567, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.csv의 1~48번 변수들에 대해 전체 분산의 80%를 설명하는 주성분들을...\n",
    "#주성분1에 대한 설명을 해보세요.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# df: 원본 데이터프레임\n",
    "df = pd.read_csv(\"data.csv\").drop(\"Pass.Fail\", axis=1)\n",
    "X = df.select_dtypes(include=\"number\").dropna()  # 숫자형만 + 결측 제거(간단 버전)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.8, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca,  index=X.index)\n",
    "\n",
    "# 분산 설명력\n",
    "explained = pca.explained_variance_ratio_\n",
    "print(\"Explained variance ratio:\", explained)\n",
    "print(\"Cumulative:\", explained.cumsum())\n",
    "X_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204c7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 주성분 개수: 20\n",
      "누적 설명력: 0.9605695116891404\n"
     ]
    }
   ],
   "source": [
    "pca95 = PCA(n_components=0.95, random_state=42)  # 누적 설명력 95% 되게끔 자동 선택\n",
    "X_pca95 = pca95.fit_transform(X_scaled)\n",
    "\n",
    "print(\"선택된 주성분 개수:\", pca95.n_components_)\n",
    "print(\"누적 설명력:\", pca95.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2def0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "X576  0.404235  0.032608  0.004703  0.022784  0.007206  0.024264  0.035614   \n",
      "X577  0.402697  0.035858  0.003710  0.038158  0.008476  0.015373  0.035501   \n",
      "X572  0.401676  0.032536  0.003232  0.024573  0.007767  0.024563  0.036321   \n",
      "X574  0.401067  0.032092  0.005139  0.022236  0.007513  0.023912  0.035015   \n",
      "X573  0.391764  0.033060  0.003698  0.024319  0.009488  0.002676  0.022870   \n",
      "X575  0.388835  0.031963  0.000666  0.019371  0.006893  0.009266  0.020738   \n",
      "X570  0.158142  0.016115  0.018647  0.005008  0.012585  0.006400  0.013268   \n",
      "X359  0.045967  0.061520  0.000722  0.004617  0.071625  0.063353  0.488998   \n",
      "X221  0.044037  0.059966  0.000500  0.000218  0.065772  0.063480  0.493775   \n",
      "X493  0.042673  0.059347  0.000573  0.001198  0.065383  0.061962  0.495357   \n",
      "\n",
      "           PC8       PC9      PC10      PC11  \n",
      "X576  0.012933  0.005157  0.004372  0.012209  \n",
      "X577  0.012579  0.024936  0.005076  0.004481  \n",
      "X572  0.009021  0.005325  0.006675  0.008641  \n",
      "X574  0.013193  0.004385  0.004964  0.010650  \n",
      "X573  0.004786  0.028753  0.012283  0.003636  \n",
      "X575  0.013996  0.027114  0.012233  0.007287  \n",
      "X570  0.023274  0.008288  0.027886  0.036648  \n",
      "X359  0.022796  0.264703  0.007604  0.004468  \n",
      "X221  0.031778  0.266663  0.006100  0.007445  \n",
      "X493  0.033743  0.266958  0.006454  0.005173  \n"
     ]
    }
   ],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,              # (변수 수, PC 수)\n",
    "    index=X.columns,\n",
    "    columns=[f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
    ")\n",
    "\n",
    "loadings_abs_top = loadings.abs().sort_values(\"PC1\", ascending=False).head(10)\n",
    "print(loadings_abs_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb661c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=2, random_state=42)),\n",
    "])\n",
    "\n",
    "X_pca = pipe.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3280085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm_train.csv에 대해서 standard scaling과 PCA를 적용해보세요\n",
    "#1번 주성분의 로딩 높은 변수 값들의 분산값 확인\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv(\"pm_train.csv\")\n",
    "scaled = StandardScaler().fit_transform( df )\n",
    "pca = PCA(n_components=0.95)\n",
    "df_pca = pca.fit_transform(scaled)\n",
    "df_pca.shape, df.shape\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,              # (변수 수, PC 수)\n",
    "    index=df.columns,\n",
    "    columns=[f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
    ")\n",
    "loadings_abs_top = loadings.abs().sort_values(\"PC1\", ascending=False).head(10)\n",
    "#print(loadings_abs_top)\n",
    "#s11, s12, s4, s7, s15\n",
    "df.var().sort_values(ascending=False)\n",
    "df_pca = pd.DataFrame(df_pca, columns=['PC'+str(i) for i in range(1,15)])\n",
    "df_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bda6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn #EDA \n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"creditset2.csv\")\n",
    "#sns.pairplot( df )  #df내 모든 변수 쌍에 대해 scatterplot, histogram\n",
    "#sns.jointplot(df, x=df.income, y=df.loan)\n",
    "#sns.heatmap( df.corr() )\n",
    "#sns.boxplot( y=df.loan, x=df.default10yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427e99a",
   "metadata": {},
   "source": [
    "# 5. ETL 대시보드 연습\n",
    "- streamlit_day3_ui.py를 참고해서 사이드바 구조로 ETL 대시보드를 만들기\n",
    "- 기능1: 파일 업로드 후 데이터프레임 생성\n",
    "- 기능2: 업로드 파일 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seaborn 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.py 파일\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.set_page_config(page_title=\"Multi Page\", layout=\"wide\")\n",
    "\n",
    "def page_home():\n",
    "    st.title(\"Home\")\n",
    "    st.subheader(\"현황\")    \n",
    "\n",
    "#upload\n",
    "def data_upload():   \n",
    "    uploaded_file = st.file_uploader(label=\"Select a file\", type=[\"csv\"])\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.write(df.head(10))\n",
    "        st.session_state[\"df\"] = df #다른 함수에서도 접근 가능하도록 세션 지정\n",
    "        st.success(\"데이터 저장 완료\")\n",
    "\n",
    "#explore\n",
    "def data_eda():  \n",
    "    tmp_df = st.session_state[\"df\"]\n",
    "    g = sns.pairplot(data=tmp_df )\n",
    "    st.pyplot(g.fig)  \n",
    "\n",
    "def data_eda2():  \n",
    "    tmp_df = st.session_state[\"df\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(data=tmp_df.corr() )\n",
    "    st.pyplot(fig)  \n",
    "\n",
    "pages = {\n",
    "    \"Home\": page_home,\n",
    "    \"Data upload\": data_upload,\n",
    "    # 내용을 추가해보세요\n",
    "}\n",
    "\n",
    "st.sidebar.subheader(\"처리 선택\")\n",
    "choice = st.sidebar.selectbox(\"이동\", list(pages.keys()))\n",
    "pages[choice]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f80845",
   "metadata": {},
   "source": [
    "# 6. ETL 대시보드 연습2\n",
    "- 기능1: API로 부터 데이터 수집하여 api_data에 csv를 생성\n",
    "- 기능2: api_data 폴더 내 csv를 읽어서 전처리 후 working directory에 하나의 csv 생성\n",
    "- 파일 생성 시 현재 연월일시분초를 파일명에 반영\n",
    "- from datetime import datetime\n",
    "- datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28442781",
   "metadata": {},
   "source": [
    "- 기능3: 수집한 csv들을 postgres db(설치 문제 있을 경우, sqlite)에 넣고, 처리된 csv는 별도 폴더(api_backup)로 이동\n",
    "- 기능4: db 내 내용 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca66e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
