{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7aa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\")\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"week1.csv\", index_col=0, parse_dates=[1])           \n",
    "                 #skiprows=#header=None,#컬럼명이 없을때                 \n",
    "df.passorfail.value_counts()\n",
    "df.select_dtypes(include=\"float\").describe()\n",
    "df.SpindleSpeed_mean.mean() #1188\n",
    "def func1(x):\n",
    "    if x >1188:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df.SpindleSpeed_mean.apply(func1)\n",
    "np.where( df.SpindleSpeed_mean > 1188, 1, 0)  \n",
    "df.isnull().mean()#.sort_values(ascending=False)\n",
    "df_num = df.select_dtypes(include=\"float\")\n",
    "df_cat = df.select_dtypes(exclude=\"float\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled = MinMaxScaler().fit_transform( df_num)\n",
    "df_num_scaled = pd.DataFrame( scaled, columns = df_num.columns, \n",
    "                             index=df_num.index)\n",
    "df_cat.ReceivedDateTime.dt\n",
    "pd.get_dummies(df_cat.passorfail.replace([0,1], [\"pass\", \"fail\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df_num_scaled, df_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af697e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1183, 40), (1085, 40))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "df_num_up, df_pass_up = SMOTE(sampling_strategy=0.2\n",
    "                              ).fit_resample( df_num, df.passorfail)  \n",
    "df_num_up.shape, df_num.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38444678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder 파일 여러개\n",
    "#data2.zip\n",
    "#images2.zip\n",
    "#작업 경로 밑 data2 밑에 파일들....\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\")\n",
    "os.listdir(\"data2\")\n",
    "\"abcde.csv\".endswith(\".csv\") \n",
    "#\"abcde.csv\".startswith(\"abc\")  #\"a-b-c\".split('-') #\"-\".join([\"a\", \"b\", \"c\"])\n",
    "csvfiles = []\n",
    "for i in os.listdir(\"data2\"):\n",
    "    if i.endswith(\".csv\"):\n",
    "        print( os.path.getsize(\"data2\\\\\"+i) )\n",
    "        csvfiles.append(i)\n",
    "[ i  for i in os.listdir(\"data2\") if i.endswith(\".csv\") ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작업경로--data2--data_politics\n",
    "#          b.txt             : \"data2\\\\\"+\"b.txt\"\n",
    "#                    a.txt   : \"data2\\\\\"+i+\"\\\\\"+\"a.txt\"\n",
    "#data_politics의 파일들 리스트를 확인해보시고, _DON.txt로 끝나는 파일들 리스트\n",
    "[i for i in os.listdir(\"data2\\\\data_politics\") if i.endswith(\"_DON.txt\")]\n",
    "import shutil\n",
    "shutil.copy(\"week1.csv\", \"data2\\\\week1.csv.bak\"  )\n",
    "#data_politics 밑에 DON 폴더 만드시고, DON.txt파일들을 DON폴더에 복사\n",
    "for i in os.listdir(\"data2\\\\data_politics\"):\n",
    "     if i.endswith(\"_DON.txt\"):\n",
    "          shutil.copy( \"data2\\\\data_politics\\\\\"+i, \n",
    "                 \"data2\\\\data_politics\\\\DON\\\\\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 밑에 keyword_data.zip 압축해제\n",
    "#keyword_data 밑의 21개 폴더 내에 파일들을 다 읽으셔서 하나의 데이터프레임\n",
    "#파일들 중에 사이즈0 \n",
    "#os.path.getsize( 파일명 )   pd.read_csv(....., header=None\n",
    "#작업경로- data2- keyword_data_21개 폴더\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\data2\\\\keyword_data\")\n",
    "result = pd.DataFrame()\n",
    "for i in os.listdir():\n",
    "    for j in os.listdir(i):\n",
    "      if os.path.getsize(i+\"\\\\\"+j) > 0:  \n",
    "        tmp = pd.read_csv(i+\"\\\\\"+j, header=None)\n",
    "        tmp.columns = [\"date\", \"value\"]\n",
    "        tmp[\"new1\"] = i+\"-\"+j\n",
    "        result = pd.concat( [result, tmp]  )  \n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80055a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agv.zip 압축 해제, 폴더들 안의 csv를 다 읽어서 하나의 데이터프레임\n",
    "#각 csv가 어느 폴더에 어느 파일이었는지를 별도의 컬럼으로 각각 기록.\n",
    "#결측치, scaling, partitiong\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\agv\")\n",
    "result = pd.DataFrame()\n",
    "for i in os.listdir():  # 두폴더를...\n",
    "    for j in os.listdir(i): #각 폴더의 파일들에 대해 반복..\n",
    "      if os.path.getsize(i+\"\\\\\"+j) > 0:  \n",
    "        tmp = pd.read_csv(i+\"\\\\\"+j, header=None, skiprows=9)\n",
    "        tmp.columns = [\"v0\",\"v1\", \"v2\", \"v3\", \"v4\"]\n",
    "        tmp[\"v5\"] = i\n",
    "        tmp[\"v6\"] = j\n",
    "        result = pd.concat( [result, tmp]  )  \n",
    "result.drop(\"v4\", axis=1, inplace=True)\n",
    "result_num = result.select_dtypes(include=\"float\")\n",
    "result_cat = result.select_dtypes(exclude=\"float\")\n",
    "result_num_scaled = pd.DataFrame( \n",
    "   MinMaxScaler().fit_transform(result_num),index=result_num.index,\n",
    "             columns = [\"v0\",\"v1\", \"v2\", \"v3\"] ) \n",
    "result2 = pd.concat(  [result_num_scaled, result_cat], axis=1)\n",
    "train, test = train_test_split(result2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3984d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\images2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  #pillow 라이브러리 설치 필요\n",
    "import numpy as np\n",
    "width=30\n",
    "height=30\n",
    "imglist = []\n",
    "labels = []\n",
    "for i in os.listdir():\n",
    "    for j in os.listdir(i):\n",
    "        img =Image.open(i+\"\\\\\"+j).convert(\"RGB\").resize((width,height))\n",
    "        imglist.append( np.array(img).reshape(width*height*3)  )\n",
    "        labels.append(i)\n",
    "df = pd.DataFrame(np.array(imglist), \n",
    "             columns=[\"v\"+str(i) for i in range(1,2701)])\n",
    "df[\"label\"] = labels\n",
    "#df에 대해서 scaling, 범주는 ohe,  데이터프레임->파티셔닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97e3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#MinMaxScaler().fit_transform(df.drop(\"label\", axis=1))\n",
    "df1 = df.drop(\"label\", axis=1)/255 #min max scaling\n",
    "df2 = pd.get_dummies(df.label)\n",
    "train, test = train_test_split( pd.concat([df1, df2], axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier().fit( df.drop(\"label\", axis=1), df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1dd44be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chair'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"..\\\\chair.jpg\").convert(\"RGB\").resize((30,30))\n",
    "tst =pd.DataFrame( np.array(img).reshape(1,2700)/255, \n",
    "             columns=[\"v\"+str(i) for i in range(1,2701)])\n",
    "model.predict(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f46dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parquet 읽고 쓰기: data.csv 파일->결측치체크->스케일링->파티셔닝\n",
    "# ->train, test 각각 파퀘로 저장\n",
    "!pip install pyarrow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debcc052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1567, 49), (1567, 49))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "df = pd.read_csv(\"data.csv\") \n",
    "df.to_parquet(\"example.parquet\")   \n",
    "#os.path.getsize(\"data.csv\"), os.path.getsize(\"example.parquet\")\n",
    "df1 = pd.read_parquet(\"example.parquet\")\n",
    "df.shape, df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0981bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\owner\\\\Documents\\\\week2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "#creditset2.csv \n",
    "#y: default10yr\n",
    "#X: age, loan, income\n",
    "#X_train, X_test, y_train, y_test 되도록 파티셔닝\n",
    "\n",
    "credit = pd.read_csv(\"creditset2.csv\")\n",
    "y = credit.default10yr\n",
    "X = credit.drop(\"default10yr\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "#################################################################\n",
    "pipe1 = Pipeline(steps=[ (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", MinMaxScaler())])\n",
    "pipe2 = Pipeline(steps=[ (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[ (\"num\", pipe1, selector(dtype_include=\"number\")),\n",
    "        (\"cat\", pipe2, selector(dtype_exclude=\"number\")) ],\n",
    "    remainder=\"drop\")  \n",
    "model = RandomForestClassifier()\n",
    "clf = Pipeline(steps=[(\"preprocess\", preprocess),(\"model\", model)])\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4405678",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) # 학습\n",
    "\n",
    "with open(\"pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump( {\"pipeline\": clf},f )\n",
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "     saved = pickle.load(f)  #dictionary\n",
    "\n",
    "saved['pipeline'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b52f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925419515226849"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "     loaded = pickle.load(f)  #dictionary\n",
    "pipe3 = loaded[\"pipeline\"]\n",
    "#1. 데이터 준비\n",
    "df = pd.read_csv(\"satimage.csv\")\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df.y\n",
    "#2. 파티셔닝\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "#3. 파이프라인.fit( X_trian, y_train)\n",
    "pipe3.fit(X_train, y_train)\n",
    "#4. 파이프라인.predict(X_test) \n",
    "pipe3.predict(X_test)  #pipe3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "     loaded = pickle.load(f)  #dictionary\n",
    "pipe3 = loaded[\"pipeline\"]\n",
    "df = pd.read_csv(\"creditset2.csv\")\n",
    "X = df.drop(\"default10yr\", axis=1)\n",
    "y = df.default10yr\n",
    "pipe3.fit(X, y)\n",
    "pipe3.predict( pd.DataFrame({\"age\":[20],\"loan\":[1000],\"income\":[5000]})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7600e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:28:18.282 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8385</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:28:18.282 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8385\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:28:23.167 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'nice-dragon'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'nice-dragon'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'hello-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:28:23.167 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'nice-dragon'\u001b[0m - Beginning flow run\u001b[35m 'nice-dragon'\u001b[0m for flow\u001b[1;35m 'hello-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Prefect\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:28:23.190 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'hello-2d0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:28:23.190 | \u001b[36mINFO\u001b[0m    | Task run 'hello-2d0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:28:23.222 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'nice-dragon'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:28:23.222 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'nice-dragon'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from prefect import flow, task\n",
    "@task\n",
    "def hello(name: str):\n",
    "    print(f\"Hello {name}\")\n",
    "@flow\n",
    "def hello_flow():\n",
    "    hello(\"Prefect\")\n",
    "hello_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51292fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
