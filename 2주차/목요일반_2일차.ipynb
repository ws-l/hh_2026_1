{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7aa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\")\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"week1.csv\", index_col=0, parse_dates=[1])           \n",
    "                 #skiprows=#header=None,#컬럼명이 없을때                 \n",
    "df.passorfail.value_counts()\n",
    "df.select_dtypes(include=\"float\").describe()\n",
    "df.SpindleSpeed_mean.mean() #1188\n",
    "def func1(x):\n",
    "    if x >1188:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df.SpindleSpeed_mean.apply(func1)\n",
    "np.where( df.SpindleSpeed_mean > 1188, 1, 0)  \n",
    "df.isnull().mean()#.sort_values(ascending=False)\n",
    "df_num = df.select_dtypes(include=\"float\")\n",
    "df_cat = df.select_dtypes(exclude=\"float\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled = MinMaxScaler().fit_transform( df_num)\n",
    "df_num_scaled = pd.DataFrame( scaled, columns = df_num.columns, \n",
    "                             index=df_num.index)\n",
    "df_cat.ReceivedDateTime.dt\n",
    "pd.get_dummies(df_cat.passorfail.replace([0,1], [\"pass\", \"fail\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df_num_scaled, df_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af697e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1183, 40), (1085, 40))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "df_num_up, df_pass_up = SMOTE(sampling_strategy=0.2\n",
    "                              ).fit_resample( df_num, df.passorfail)  \n",
    "df_num_up.shape, df_num.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38444678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder 파일 여러개\n",
    "#data2.zip\n",
    "#images2.zip\n",
    "#작업 경로 밑 data2 밑에 파일들....\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\")\n",
    "os.listdir(\"data2\")\n",
    "\"abcde.csv\".endswith(\".csv\") \n",
    "#\"abcde.csv\".startswith(\"abc\")  #\"a-b-c\".split('-') #\"-\".join([\"a\", \"b\", \"c\"])\n",
    "csvfiles = []\n",
    "for i in os.listdir(\"data2\"):\n",
    "    if i.endswith(\".csv\"):\n",
    "        print( os.path.getsize(\"data2\\\\\"+i) )\n",
    "        csvfiles.append(i)\n",
    "[ i  for i in os.listdir(\"data2\") if i.endswith(\".csv\") ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작업경로--data2--data_politics\n",
    "#          b.txt             : \"data2\\\\\"+\"b.txt\"\n",
    "#                    a.txt   : \"data2\\\\\"+i+\"\\\\\"+\"a.txt\"\n",
    "#data_politics의 파일들 리스트를 확인해보시고, _DON.txt로 끝나는 파일들 리스트\n",
    "[i for i in os.listdir(\"data2\\\\data_politics\") if i.endswith(\"_DON.txt\")]\n",
    "import shutil\n",
    "shutil.copy(\"week1.csv\", \"data2\\\\week1.csv.bak\"  )\n",
    "#data_politics 밑에 DON 폴더 만드시고, DON.txt파일들을 DON폴더에 복사\n",
    "for i in os.listdir(\"data2\\\\data_politics\"):\n",
    "     if i.endswith(\"_DON.txt\"):\n",
    "          shutil.copy( \"data2\\\\data_politics\\\\\"+i, \n",
    "                 \"data2\\\\data_politics\\\\DON\\\\\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 밑에 keyword_data.zip 압축해제\n",
    "#keyword_data 밑의 21개 폴더 내에 파일들을 다 읽으셔서 하나의 데이터프레임\n",
    "#파일들 중에 사이즈0 \n",
    "#os.path.getsize( 파일명 )   pd.read_csv(....., header=None\n",
    "#작업경로- data2- keyword_data_21개 폴더\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\data2\\\\keyword_data\")\n",
    "result = pd.DataFrame()\n",
    "for i in os.listdir():\n",
    "    for j in os.listdir(i):\n",
    "      if os.path.getsize(i+\"\\\\\"+j) > 0:  \n",
    "        tmp = pd.read_csv(i+\"\\\\\"+j, header=None)\n",
    "        tmp.columns = [\"date\", \"value\"]\n",
    "        tmp[\"new1\"] = i+\"-\"+j\n",
    "        result = pd.concat( [result, tmp]  )  \n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80055a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agv.zip 압축 해제, 폴더들 안의 csv를 다 읽어서 하나의 데이터프레임\n",
    "#각 csv가 어느 폴더에 어느 파일이었는지를 별도의 컬럼으로 각각 기록.\n",
    "#결측치, scaling, partitiong\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\agv\")\n",
    "result = pd.DataFrame()\n",
    "for i in os.listdir():  # 두폴더를...\n",
    "    for j in os.listdir(i): #각 폴더의 파일들에 대해 반복..\n",
    "      if os.path.getsize(i+\"\\\\\"+j) > 0:  \n",
    "        tmp = pd.read_csv(i+\"\\\\\"+j, header=None, skiprows=9)\n",
    "        tmp.columns = [\"v0\",\"v1\", \"v2\", \"v3\", \"v4\"]\n",
    "        tmp[\"v5\"] = i\n",
    "        tmp[\"v6\"] = j\n",
    "        result = pd.concat( [result, tmp]  )  \n",
    "result.drop(\"v4\", axis=1, inplace=True)\n",
    "result_num = result.select_dtypes(include=\"float\")\n",
    "result_cat = result.select_dtypes(exclude=\"float\")\n",
    "result_num_scaled = pd.DataFrame( \n",
    "   MinMaxScaler().fit_transform(result_num),index=result_num.index,\n",
    "             columns = [\"v0\",\"v1\", \"v2\", \"v3\"] ) \n",
    "result2 = pd.concat(  [result_num_scaled, result_cat], axis=1)\n",
    "train, test = train_test_split(result2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3984d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('c:\\\\users\\\\owner\\\\Documents\\\\week2\\\\images2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  #pillow 라이브러리 설치 필요\n",
    "import numpy as np\n",
    "width=30\n",
    "height=30\n",
    "imglist = []\n",
    "labels = []\n",
    "for i in os.listdir():\n",
    "    for j in os.listdir(i):\n",
    "        img =Image.open(i+\"\\\\\"+j).convert(\"RGB\").resize((width,height))\n",
    "        imglist.append( np.array(img).reshape(width*height*3)  )\n",
    "        labels.append(i)\n",
    "df = pd.DataFrame(np.array(imglist), \n",
    "             columns=[\"v\"+str(i) for i in range(1,2701)])\n",
    "df[\"label\"] = labels\n",
    "#df에 대해서 scaling, 범주는 ohe,  데이터프레임->파티셔닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97e3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#MinMaxScaler().fit_transform(df.drop(\"label\", axis=1))\n",
    "df1 = df.drop(\"label\", axis=1)/255 #min max scaling\n",
    "df2 = pd.get_dummies(df.label)\n",
    "train, test = train_test_split( pd.concat([df1, df2], axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier().fit( df.drop(\"label\", axis=1), df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1dd44be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chair'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"..\\\\chair.jpg\").convert(\"RGB\").resize((30,30))\n",
    "tst =pd.DataFrame( np.array(img).reshape(1,2700)/255, \n",
    "             columns=[\"v\"+str(i) for i in range(1,2701)])\n",
    "model.predict(tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
