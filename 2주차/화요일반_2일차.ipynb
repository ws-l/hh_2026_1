{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"c:\\\\Users\\\\owner\\\\Downloads\\\\week1.csv\",\n",
    "                   index_col=0)#,\n",
    "#                   parse_dates=[1])\n",
    "pd.to_datetime(data.ReceivedDateTime)\n",
    "pd.get_dummies( data.passorfail ) #One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfae977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_num = data.select_dtypes(include=\"float\")\n",
    "data_cat = data.select_dtypes(exclude=\"float\")\n",
    "\n",
    "data_num.describe()\n",
    "np.where(data_num.SpindleSpeed_mean >1188, 1, 0)\n",
    "\n",
    "def func1(x):\n",
    "    if x>1188:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data_num.SpindleSpeed_mean.apply(func1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8732736",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat( [data_num, data_cat], axis=1 )\n",
    "\n",
    "pd.to_datetime(data.ReceivedDateTime)\n",
    "pd.get_dummies( data.passorfail ) #One Hot Encoding\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split( data2, \n",
    "                               stratify=data2.passorfail )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d951e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07605387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1085, 40) (1085,)\n",
      "(1183, 40) (1183,) passorfail\n",
      "0    986\n",
      "1    197\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X, y = SMOTE(sampling_strategy = 0.2 , # \n",
    "             k_neighbors = 5,\n",
    "             random_state=1).fit_resample(data_num, \n",
    "                                           data.passorfail)\n",
    "print( data_num.shape, data.passorfail.shape )\n",
    "print( X.shape, y.shape, y.value_counts())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data2')\n",
    "for i in files:\n",
    "    if i.endswith('.csv'):\n",
    "        print(i)\n",
    "[ i for i in os.listdir('data2') if i.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cef639",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"roy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe55eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 폴더 밑 data_politics의 파일들 중에서,\n",
    "#ROY라는 사람의 발언만 모아서 data2/data_politics/roy폴더에 \n",
    "#옮기세요\n",
    "files3 = [ i for i in os.listdir(\"data_politics\") \n",
    " if i.endswith(\"_ROY.txt\")]\n",
    "for i in files3:\n",
    "    shutil.move(\"data_politics\\\\\"+i, \n",
    "                \"roy\\\\\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"keyword_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd28c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_data 폴더 밑의 폴더들의 파일들을 \n",
    "#하나의 데이터프레임으로 합쳐보세요\n",
    "import pandas as pd\n",
    "result = pd.DataFrame()\n",
    "for i in ['1', '2', '3']:\n",
    "  for j in ['1', '2', '3']:\n",
    "    for q in ['1', '2']:\n",
    "      tmp = 'k'+i+'_'+j+'_'+q\n",
    "      for t in os.listdir(tmp):\n",
    "        file = tmp+\"\\\\\"+t\n",
    "        if os.path.getsize(file) > 0:\n",
    "          df_tmp = pd.read_csv(tmp+\"\\\\\"+t, header=None)\n",
    "          result = pd.concat([result, df_tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a44edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agv.zip 다운로드->하나의 데이터프레임\n",
    "# -> imputing->scaling->OHE->파퀘 저장, #폴더값이 Y가 되도록 지정해주세요.\n",
    "#pd.read_csv(    , skiprows= )\n",
    "os.chdir(\"c:\\\\users\\\\owner\\\\agv\")\n",
    "folders = os.listdir()\n",
    "result = pd.DataFrame()\n",
    "for cat in folders: \n",
    " for i in os.listdir(cat):  \n",
    "  tmp = pd.read_csv(cat+\"\\\\\"+i, skiprows=9, header=None )\n",
    "  tmp[\"label\"] = cat \n",
    "  result = pd.concat( [result, tmp] ) \n",
    "result.columns = [\"v1\", \"v2\", \"v3\",\"v4\",\"v5\",\"label\"]\n",
    "result = result.drop(\"v5\", axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform( result.iloc[:, 0:4] )\n",
    "X = pd.DataFrame( scaled, columns=[\"v1\", \"v2\", \"v3\", \"v4\"])\n",
    "y = pd.get_dummies(result[\"label\"])\n",
    "y.index=X.index\n",
    "result2 = pd.concat( [X,y], axis=1, ignore_index=True)\n",
    "result2.to_parquet(\"agv.parquet\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"c:\\\\Users\\\\owner\\\\images2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for cat in [\"camera\", \"chair\"]: \n",
    " for i in os.listdir(cat):  \n",
    "    img = Image.open(cat+\"\\\\\"+i)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((30, 30))\n",
    "    data=np.array(img)\n",
    "    X.append(data)\n",
    "    Y.append(cat)\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "X = X.reshape( 112, 2700)  #4차원->2차원\n",
    "X = X/255  #minmaxscaling\n",
    "Y = pd.get_dummies(Y) #OHE\n",
    "#partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,Y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit( X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6994d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c67df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52fd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21276ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
